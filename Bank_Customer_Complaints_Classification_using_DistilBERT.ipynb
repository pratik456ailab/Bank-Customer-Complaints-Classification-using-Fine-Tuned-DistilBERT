{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Packages"
      ],
      "metadata": {
        "id": "lDs9DRHeU0lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install accelerate -U\n",
        "!pip -q install transformers[torch]\n",
        "!pip -q install datasets\n",
        "#Restart after installing"
      ],
      "metadata": {
        "id": "4UkbG0gAAOzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "fo9M10uMU5Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Textwrp function to display the output in a better format\n",
        "# This is an optional function, you can ignore it\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def wrap_display():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', wrap_display)"
      ],
      "metadata": {
        "id": "vDK0x4ifHzdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bank Complaints Data"
      ],
      "metadata": {
        "id": "nYFE5O8RB4MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/venkatareddykonasani/Datasets/raw/master/Bank_Customer_Complaints/complaints_v2.zip\n",
        "!unzip -o complaints_v2.zip\n",
        "complaints_data = pd.read_csv(\"/content/complaints_v2.csv\")\n",
        "complaints_data.head()"
      ],
      "metadata": {
        "id": "BGkqrKxCfrHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use distilbert model without finetunung"
      ],
      "metadata": {
        "id": "hqmjOcoOB-ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distil bert model\n",
        "from transformers import pipeline\n",
        "distilbert_model = pipeline(task=\"text-classification\",\n",
        "                            model=\"distilbert-base-uncased\",\n",
        "                            )"
      ],
      "metadata": {
        "id": "8BJkxMer_wjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data=complaints_data.sample(100, random_state=42)\n",
        "sample_data[\"text\"]=sample_data[\"text\"].apply(lambda x: \" \".join(x.split()[:350]))\n",
        "sample_data[\"bert_predicted\"] = sample_data[\"text\"].apply(lambda x: distilbert_model(x)[0][\"label\"])\n",
        "#Default prediction is not a number LABEL_1, LABEL_0\n",
        "sample_data[\"bert_predicted_num\"]=sample_data[\"bert_predicted\"].apply(lambda x: x[-1])\n",
        "sample_data[\"bert_predicted_num\"] = sample_data[\"bert_predicted_num\"].astype(int)\n",
        "sample_data.head()"
      ],
      "metadata": {
        "id": "2WbHzWMRDiRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy of the model without fine-tuning"
      ],
      "metadata": {
        "id": "CRx_9gXrklH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(sample_data[\"label\"], sample_data[\"bert_predicted_num\"])\n",
        "print(cm)\n",
        "accuracy=cm.diagonal().sum()/cm.sum()\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "W_LxeuwUIg6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project - Finetuning the model with our data\n"
      ],
      "metadata": {
        "id": "8IoArWg3ksvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install accelerate -U\n",
        "!pip -q install transformers[torch]\n",
        "!pip -q install datasets"
      ],
      "metadata": {
        "id": "wvhIoOLQBG8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import load_dataset, DatasetDict, ClassLabel, Dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch"
      ],
      "metadata": {
        "id": "jZT4RxigoO3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The target variable must be named as \"label\" - Verify it, before proceeding\n",
        "print(sample_data.columns)"
      ],
      "metadata": {
        "id": "BF1wh7rY4MtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sample_data = Dataset.from_pandas(sample_data)\n",
        "# Split the dataset into training and testing sets\n",
        "train_test_split = Sample_data.train_test_split(test_size=0.2)  # 80% training, 20% testing\n",
        "dataset = DatasetDict({\n",
        "    'train': train_test_split['train'],\n",
        "    'test': train_test_split['test']\n",
        "})\n",
        "dataset"
      ],
      "metadata": {
        "id": "cXivZhOxjQtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the tokenizer"
      ],
      "metadata": {
        "id": "mYxjyEgRR2p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'} )\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "khB_bZv0lcXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Train the model"
      ],
      "metadata": {
        "id": "l_Q_vJOISAtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',\n",
        "                                                            num_labels=2,\n",
        "                                                            pad_token_id=tokenizer.eos_token_id) # Adjust num_labels as needed\n",
        "model"
      ],
      "metadata": {
        "id": "LcBw9CWmf0_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_bert_custom\",\n",
        "    num_train_epochs=1,\n",
        "    logging_dir=\"./logs_bert_custom\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['test'],\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "bbMzSADKvCtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory where you want to save your model and tokenizer\n",
        "model_dir = \"./distilbert_finetuned\"\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(model_dir)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "#Save the model with\n",
        "trainer.save_model('Distilbert_CustomModel_10K')"
      ],
      "metadata": {
        "id": "FIVONC0H7YZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(text):\n",
        "  new_complaint=text\n",
        "  inputs=tokenizer(new_complaint, return_tensors=\"pt\")\n",
        "  inputs = inputs.to(torch.device(\"cuda:0\"))\n",
        "  outputs=model(**inputs)\n",
        "  predictions=outputs.logits.argmax(-1)\n",
        "  predictions=predictions.detach().cpu().numpy()\n",
        "  return(predictions)\n",
        "\n",
        "sample_data[\"finetuned_predicted\"]=sample_data[\"text\"].apply(lambda x: make_prediction(str(x))[0])\n",
        "sample_data.sample(10)"
      ],
      "metadata": {
        "id": "x5zPdvspOrjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Create the confusion matrix\n",
        "cm1 = confusion_matrix(sample_data[\"label\"], sample_data[\"finetuned_predicted\"])\n",
        "print(cm1)\n",
        "accuracy1=cm1.diagonal().sum()/cm1.sum()\n",
        "print(accuracy1)"
      ],
      "metadata": {
        "id": "o8BsIrTyWc72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading a pre-built model and making prediction"
      ],
      "metadata": {
        "id": "vIwrPpOpzawh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to donwloading the distilbert model\n",
        "!gdown --id 1785J3ir19RaZP3ebbFvWUX88PMaBouro -O distilbert_finetuned_V1.zip\n",
        "!unzip -o -j distilbert_finetuned_V1.zip -d distilbert_finetuned_V1\n",
        "\n",
        "model_v1 = DistilBertForSequenceClassification.from_pretrained('/content/distilbert_finetuned_V1')\n",
        "model_v1.to(\"cuda:0\")"
      ],
      "metadata": {
        "id": "kmhTs6AAzFDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(text):\n",
        "  new_complaint=text\n",
        "  inputs=tokenizer(new_complaint, return_tensors=\"pt\")\n",
        "  inputs = inputs.to(torch.device(\"cuda:0\"))\n",
        "  outputs=model_v1(**inputs)\n",
        "  predictions=outputs.logits.argmax(-1)\n",
        "  predictions=predictions.detach().cpu().numpy()\n",
        "  return(predictions)\n"
      ],
      "metadata": {
        "id": "HCJz8FD99xcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data_large=complaints_data.sample(n=1000, random_state=55)\n",
        "sample_data_large[\"finetuned_predicted\"]=sample_data_large[\"text\"].apply(lambda x: make_prediction(str(x)[:350])[0])"
      ],
      "metadata": {
        "id": "99Z7s9P-C-hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data_large[\"finetuned_predicted\"]"
      ],
      "metadata": {
        "id": "qLAOpceYfkWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Create the confusion matrix\n",
        "cm1 = confusion_matrix(sample_data_large[\"label\"], sample_data_large[\"finetuned_predicted\"])\n",
        "print(cm1)\n",
        "accuracy1=cm1.diagonal().sum()/cm1.sum()\n",
        "print(accuracy1)"
      ],
      "metadata": {
        "id": "b9Iq2KJD-AJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Model on HuggingFace hub"
      ],
      "metadata": {
        "id": "vm1l0v6Dx-jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install -U ipykernel #for executing the commands\n"
      ],
      "metadata": {
        "id": "S6SPRqIiynQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n"
      ],
      "metadata": {
        "id": "rcqXDgoizIyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1785J3ir19RaZP3ebbFvWUX88PMaBouro -O distilbert_finetuned_V1.zip\n",
        "!unzip -o -j distilbert_finetuned_V1.zip -d distilbert_finetuned_V1\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('/content/distilbert_finetuned_V1')\n"
      ],
      "metadata": {
        "id": "9gmtZkvqDJNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"YOUR ACCESS TOKEN\""
      ],
      "metadata": {
        "id": "iJmy5o-I0SGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "#To get Auth token: Profile >> Settings >>Access Token"
      ],
      "metadata": {
        "id": "hs-qSjk-z0dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"pratik456ailab/Bank_distil_bert_10K\")"
      ],
      "metadata": {
        "id": "NRPRvUh-0esS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the model from HuggingFace hub"
      ],
      "metadata": {
        "id": "JFnoFMsHBEw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=DistilBertForSequenceClassification.from_pretrained(\"pratik456ailab/Bank_distil_bert_10K\")"
      ],
      "metadata": {
        "id": "7FbKUERK0k5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "GsKSd1EM1DS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "!wget https://github.com/venkatareddykonasani/Datasets/raw/master/Bank_Customer_Complaints/complaints_v2.zip\n",
        "!unzip -o complaints_v2.zip\n",
        "complaints_data = pd.read_csv(\"/content/complaints_v2.csv\")\n",
        "list(complaints_data[\"text\"].head())"
      ],
      "metadata": {
        "id": "qGd2quFz1Hss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "PyRrPXtF2YFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complaint=\"\"\"\n",
        "payment history missing credit report made mistake put account forbearance without authorization knowledge matter fact automatic payment setup month monthly mortgage paid full noticed issue account marked forbearance credit report tried get new home loan another new bank contacted immediately asked fix error provide letter detail please see asks forbearance issue seemed fixed however credit report payment history missing new bank able approve new loan issue missing payment history contacted time since phone ask thing report payment history transunion fix missing data issue provide letter show account never forbearance payment history past month however waiting week countless email phone call talk multiple supervisor able get either one thing without issue fixed new bank process new loan application therefore need help immediately get fixed\n",
        "\"\"\"\n",
        "\n",
        "inputs=tokenizer(complaint, return_tensors=\"pt\")\n",
        "outputs=model(**inputs)\n",
        "predictions=outputs.logits.argmax(-1)\n",
        "predictions=predictions.detach().cpu().numpy()\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "k_2szgSb1rcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web App Creation"
      ],
      "metadata": {
        "id": "fTFBcRMfBM6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "streamlit\n",
        "numpy\n",
        "pandas\n",
        "torch\n",
        "transformers\n",
        "huggingface_hub"
      ],
      "metadata": {
        "id": "oIkhfFOwkLY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Opz4IsR8mOH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('pratik456ailab/Bank_distil_bert_10K')\n",
        "\n",
        "st.title(\"Bank Complaints Categorization\")\n",
        "st.write(\"Sample Complaints are given below\")\n",
        "Sample_Complaints = [\n",
        "    {\"Sentence\": \"Credit Report - payment history missing credit report made mistake put account forbearance without authorization \"},\n",
        "    {\"Sentence\": \"Retail Related - forwarded message cc sent friday pdt subject final legal payment well fargo well fargo clearly wrong need look actually opened account see court hearing several different government agency \"}\n",
        "]\n",
        "st.table(Sample_Complaints)\n",
        "user_input = st.text_input(\"Enter a complaint:\")\n",
        "button=st.button(\"Classify\")\n",
        "\n",
        "d={\n",
        "    0: \"Credit reporting\",\n",
        "    1: \"Mortgage and Others\"\n",
        "}\n",
        "\n",
        "if user_input and button:\n",
        "  inputs=tokenizer(user_input, return_tensors=\"pt\")\n",
        "  outputs=model(**inputs)\n",
        "  predictions=outputs.logits.argmax(-1)\n",
        "  predictions=predictions.detach().cpu().numpy()\n",
        "  print(predictions)\n",
        "  st.write(\"Prediction :\" , d[predictions[0]])\n"
      ],
      "metadata": {
        "id": "6ZYun4Kf2UkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n",
        "\n",
        "#This sometimes doesn't work on Chrome"
      ],
      "metadata": {
        "id": "YIaHczsX-wT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m4zPgyAw_-ko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}